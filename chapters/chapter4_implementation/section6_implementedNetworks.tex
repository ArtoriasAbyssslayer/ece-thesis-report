\section{Υλοποιημένα Δίκτυα και Παράμετροι}
\par
    Ένα μεγάλο μέρος των δικτύων έμμεσης διαφορίσιμης αποτύπωσης, που έχουν χρησιμοποιηθεί, βασίζονται σε \enit{PyTorch} και έχουν δανειστεί από το αποθετήριο του IDR \footnote{διατίθεται με MIT άδεια χρήσης, δηλαδή μπορεί να χρησιμοποιηθεί και να επεκταθεί για ερευνητικούς σκοπούς όπως γίνεται στην προκειμένη περίπτωση} \href{https://github.com/lioryariv/idr}{https://github.com/lioryariv/idr}. Ευχαριστούμε την παραπάνω ερευνητική εργασία που επέτρεψε να δοθεί έμφαση στο κομμάτι των βαθιών δικτύων κωδικοποίησης των πεδίων που αποτυπώνει. 
\par
    Βέβαια έχουν γίνει αρκετές παραμετροποίησεις στον κώδικα του δικτύου στο σημείο που να μην λειτουργούν με τον ίδιο τρόπο επομένως έχει δημιουργηθεί και ειδικό αποθετήριο για την παρούσα εργασία που δίνεται στο παράρτημα (βλ.\ref{chapter:appendix} Παράρτημα Γ Δείγματα Αλγορίθμων). 
\par    
    Το δίκτυο γεωμετρικής εκτίμησης της επιφάνειας,  \(F(p;\theta)=(f(x;\theta), z(x;\theta)) \in \mathbb{R} \times \mathbb{R}^{256} \), είναι ένα δίκτυο MLP 8 επιπέδων πλάτους 512 νευρώνων και αποτελεί ResNet (\enit{Residual Net}) γιατί πραγματοποιεί διακοπή της σύνδεση στο 4ο επίπεδο όπου εισάγονται ξανά οι είσοδοι ώστε να διατηρηθεί η αριθμητική τιμή των κλίσεων των βαρών(και να μην χαθεί η πληροφορία των δεδομένων). Οι παράμετροι των γραμμικών του επιπέδων, αρχικοποιούνται ώστε να περιγράφει μια περιβάλλουσα μοναδιαία σφαίρα ενώ οι παράμετροι $z$ αποτελούν τα \enit{DeepSDF} χαρακτηριστικά τα οποία βελτιώνονται μετασχηματίζοντας την είσοδο με την βαθιά δίκτυα κωδικοποίησης. Σημαντική αλλαγή είναι πως χρησιμοποιείται συνάρτηση πυκνότητας πιθανότητας Laplace στο μέρος της εξόδου που αφορά το σημείο της επιφάνειας μαζί με συνάρτηση υπερβολικής εφαπτομένης ώστε να προσεγγίζουμε ομαλά με προτίμηση από έξω δηλαδή από τιμές SDF θετικές και να κόβονται ακραίες τιμές που υπερβαίνουν την μοναδιαία σφαίρα. Αυτή η τακτική \enit{Truncated SDF} χρησιμοποιείται συχνά ως μέτρο ευστάθειας, ειδικά όταν υπάρχουν έξοδοι που δίνουν πολύ μεγάλα βάρη στην κωδικοποίηση της εισόδου. 

    Το δίκτυο αποτύπωσης $\mathcal{M}(\hat{p}, \hat{n}, \hat{z}, \boldsymbol{w};\gamma) \in \mathbb{R}^3$, δίνει την εκτίμηση του χρώματος στο πρότυπο [R, G, B] του pixel της εικόνας από το οποίο διέρχεται η ακτίνα με μοναδιαίο διάνυσμα κατεύθυνσης $\boldsymbol{w}$. Είναι ένα MLP 4 επιπέδων με ίδιο πλήθος νευρώνων με το δίκτυο γεωμετρικής εκτίμησης δηλαδή 512. Η είσοδος του δικτύου αποτελεί συνενωμένο το διάνυσμα διαφορίσιμων σημείων, κάθετων διανυσμάτων, διανυσμάτων όψης και βαθιών χαρακτηριστικών SDF ώστε να μπορέσει να υλοποιηθεί η έμμεση εκπαίδευση του δικτύου γεωμετρίας από τις εικόνες με μια συνεχή συνάρτηση που αποτελεί \textbf{P-Universal} σύστημα αποτύπωσης (βλ.\ref{appendix:phong} Phong Reflection).

    Τα προαναφερθέντα δίκτυα, είναι διαφοροποιημένα στα μέτρα της εργασίας και είναι απλά MLP. Η παρούσα έρευνα αποτελεί κυρίως την υλοποίηση των παρακάτω δικτύων και την συνολική ρύθμιση της συνολικής γραμμής του αλγορίθμου ώστε να δουλεύει σωστά με την επέκταση (\enit{<<plug-in>>}) των δίκτυα κωδικοποίησης.

    Οι πυρήνες συναρτήσεων μετασχηματισμού και τα δίκτυα υψηλοσυχνοτικής κωδικοποίησης εφαρμόζονται κατά το εμπρόσθιο πέρασμα των παραπάνω δικτύων στις εισόδους τους και επιστρέφουν κωδικοποιημένα σημεία διάστασης 259 (όση δηλαδή το \enit{feature vector} $z$ μαζί με την διάσταση της εισόδου). Τα δίκτυα γεωμετρίας και αποτύπωσης, εκτελούν τον υπολογισμό προς τα πίσω  των κλίσεων των σφαλμάτων και στα δίκτυα κωδικοποίησης. 

     Οι αλγόριθμοι και τα δίκτυα κωδικοποίησης, επίσης, μπορούν να αναπαριστούν λόγω της ιδιαίτερης δομής τους με MLP στρώματα και από μόνα τους σημεία στον χώρο (αναπαριστούν συνεχείς συναρτήσεις). Χρησιμοποιούνται κυρίως όμως, ως δίκτυα μετασχηματισμού της εισόδου στην παρούσα εργασία καθώς η είσοδος και η έξοδός τους δεν χειρίζεται με τρόπο ώστε να αναπαριστούν πεδία πληρότητας σημείων (\enit{οccupancy fields}).  Οι παράμετροι  τους δίνονται στα πειράματα.

\subsubsection{Πλήρως Συγχωνευμένα Δίκτυα Βαθιάς Κωδικοποίησης TinyCudaNN}
    H \enit{Nvidia} παρέχει μια βιβλιοθήκη σύνθεσης πλήρως συγχωνευμένων δικτύων \enit{MLP} που υπολογίζουν το \enit{Multi-Resolution HashGrid Encoding} της οποίας η χρήση γίνεται στα δίκτυα κωδικοποίησης που αναφέρθηκαν προηγουμένως (ως εναλλακτική στα δίκτυα που υλοποιήθηκαν αρχικά). Ο λόγος γίνεται για την \enit{TinyCudaNN}\cite{tinycudann}, μια πλήρως παραλληλοποιημένη επέκταση της \enit{PyTorch} που δίνει την δυνατότητα χρήσης και πράξεων με αριθμούς κινητής υποδιαστολής μισής ακρίβειας (\enit{Half operations}), για όσους διαθέτουν νέες μορφές καρτών γραφικών (διαθέτουν ειδική μονάδα επεξεργασίας για γραφικά που βασίζονται στην ιχνηλάτιση ακτίνας - \enit{RT cores}). Τα δίκτυα αυτά είναι σε θέση βάζοντας περισσότερους κόμβους σε κάθε επίπεδο αλλά διατηρώντας μικρο πλάτος δικτύων (εξ ου και το \enit{tiny} στην ονομασία τους), να επιταχύνουν την διαδικασία εκπαίδευσης των χωρικών πλεγμάτων των MLPs που αναπαριστούν την κωδικοποίηση συνταγμένων \enit{Hash}. Επειδή η ταχύτητα εκπαίδευσης είναι κρίσιμη παράμετρος ερευνήθηκαν και μέθοδοι \enit{CUDA} δικτύων ως \enit{C++ binding} επεκτάσεις στην \enit{PyTorch} του \enit{HashGrid Encoding} και δημιουργήθηκαν κάποια από τα προαναφερθέν δίκτυα με την χρήση της βιβλιοθήκης αλλά και με χρήση \enit{CUDA} υπολογισμών\footnote{Επειδή δεν υπήρχε διαθέσιμη σύγχρονη μορφή κάρτας δεν μπορούσαν να χρησιμοποιηθούν \enit{half operations} ούτε \enit{mixed precision} εκπαίδευση αλλά η βιβλιοθήκη παρέχει δίκτυο συμβατό που το ονομάζει \enit{CutlassMLP}}.

    
